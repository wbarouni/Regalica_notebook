version: "3.8"

volumes:
  pg_data:
  redis_data:
  ollama_models:
  uploads:
  embedder_cache:
  reranker_cache:

services:
  postgres:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_DB: notebook
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./initdb:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d notebook"]
      interval: 5s
      timeout: 5s
      retries: 30
      start_period: 10s
    # Change host port to avoid conflicts with a local Postgres
    ports: ["5433:5432"]
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 30
      start_period: 5s
    ports: ["6379:6379"]
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_models:/root/.ollama
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:11434/api/version"]
      interval: 10s
      timeout: 5s
      retries: 120
      start_period: 30s
    # Change host port to avoid conflicts with a locally running Ollama
    ports: ["11435:11434"]
    restart: unless-stopped

  embedder:
    build: ../../embedder
    environment:
      EMBED_MODEL_NAME: ${EMBED_MODEL_NAME:-intfloat/multilingual-e5-large}
      HOST: 0.0.0.0
      PORT: 8000
    volumes:
      - embedder_cache:/root/.cache
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get(\'http://localhost:8000/health\')"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 120s
    restart: unless-stopped
    ports: ["8000:8000"]

  reranker:
    build: ../../reranker
    environment:
      RERANKER_MODEL_NAME: ${RERANKER_MODEL_NAME:-BAAI/bge-reranker-v2-m3}
      HOST: 0.0.0.0
      PORT: 8001
    volumes:
      - reranker_cache:/root/.cache
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get(\'http://localhost:8001/health\')"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    restart: unless-stopped
    ports: ["8001:8001"]

  backend:
    build: ../../backend
    environment:
      SERVER_PORT: 5200
      LOG_LEVEL: info
      DB_URL: postgres://postgres:postgres@postgres:5432/notebook
      DB_SCHEMA: nbk
      MAX_UPLOAD_MB: 100
      EMBED_API_URL: http://embedder:8000
      EMBED_MODEL_NAME: ${EMBED_MODEL_NAME:-intfloat/multilingual-e5-large}
      CHUNK_TOKENS_MAX: 1800
      CHUNK_OVERLAP_PCT: 0.25
      ALLOWED_MIME: application/pdf,application/vnd.openxmlformats-officedocument.wordprocessingml.document,text/html,text/plain
      OCR_ENABLE: false
    volumes:
      - uploads:/app/uploads
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:5200/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 15s
    ports: ["5200:5200"]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
      embedder:
        condition: service_healthy
      reranker:
        condition: service_healthy
    restart: unless-stopped

  frontend:
    build: ../../frontend
    environment:
      NG_APP_API_BASE_URL: http://localhost:5200
      NG_APP_MAX_UPLOAD_MB: 100
      NG_APP_PAGE_SIZE: 20
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:80"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    # Use 4300 on host to avoid clashing with local ng serve on 4200
    ports: ["4300:80"]
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
